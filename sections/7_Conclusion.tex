\section{Conclusion}
\label{lConclusion}

\subsection{Summary}
\label{lSummary}

This work addressed the consistent migration of stream processing \gls{pe}s between nodes in the fog. This was motivated by outlining the need for \gls{pe} migration in fog computing applications to address a multitude of characteristic constraints and requirements in fog computing. The migration allows for workload mobility, which can be utilized to minimize latency, react to resource constraints, or address privacy issues. This becomes increasingly important with the proliferation of connected \gls{iot} devices, which can significantly profit from fog computing.\par

To lay the groundwork, the background section focused on the intricacies of fog computing and event-based stream processing. After introducing the concept of stateful and stateless \gls{pe}s, the operator state was introduced as a proper representation of state for the use case of stream-processing. The operator state is composed of the routing, processing, and buffer state. This abstraction serves to describe the state of stream processing \gls{pe}s.\par

Other works addressing the migration of stateful applications in the fog were subsequently presented. While early research focused on live migration of \gls{vm}s, more recently, the focus shifted to the migration of containerized applications, which proves to be less resource-intensive and better suited for the migration of applications in the fog. Some authors take a different approach by utilizing explicit state-management at the application-level, instead of migrating the whole operating system with the applications. These approaches resemble the ones introduced in the literature concerning state-management in data processing, which was thoroughly examined next. In these works, state is used not only for migration but also to provide scalability and fault tolerance.\par

Based on the related works, a conceptual framework addressing the research questions was developed. It adopts application-level state-management and addresses the requirements emerging from the research questions. The migration of running and interrupted \gls{pe}s are treated separately. The migration of a running \gls{pe} uses the current operator state, which is obtained from the \gls{pe} on the origin node, to start the \gls{pe} on the target node. This means that processing can be picked up on the target node at the same point it was interrupted on the origin node. In contrast, the migration of an interrupted \gls{pe} (a \gls{pe} that is unreachable) is performed using a previously acquired checkpoint of the \gls{pe}'s state. This checkpoint is used to restart the \gls{pe} on the target node and to recreate the correct operator state. Checkpoints are obtained through \gls{dlac}, which addresses \gls{pe} availability, fault tolerance, and global checkpoint availability by combining periodic asynchronous local checkpointing with periodic asynchronous global checkpointing.\par

As proof of concept, the developed conceptual framework was implemented into Apache StreamPipes in chapter \ref{lImplementation}. At first, the fundamental modifications and extensions to StreamPipes, enabling the migration, were implemented. Next, the implementation of the \textit{\acrshort{pe} live migration}, and the \textit{\acrshort{pe} restoration} procedure was presented. The implementation addresses the requirements set in the previous chapter and shows a possible realization of the conceptual framework, addressing different challenges that are not covered by the conceptual framework.\par

This implemented proof of concept was evaluated in three experiments. The first experiment evaluated the \textit{\acrshort{pe} live migration} and showed that increased network delay and bigger state sizes impact the \gls{pe} downtime and the overall migration duration. However, a negative effect on the consistency of the results could not be observed. In the next experiment, the \textit{\acrshort{pe} restoration} was examined. The results revealed a correlation between the number of events to be reprocessed and the duration of reprocessing. A similar correlation was observed between the number of intermediary events to be processed and the duration of processing them. The third experiment examined the checkpointing performance for different state sizes. The results show that the share of the processing state serialization in the checkpointing duration increased with the state-size.\\
After that, the acquired results were discussed, and the limitations of this thesis were outlined. In the discussion, it was established that the implementation does predominantly satisfy the requirements. Shortcomings were laid out in the limitations section.\\
In this chapter, this thesis is contrasted against related works. After that, the limitations are followed up with suggestions for future research that could expand on this thesis.\par


This thesis expands on related work by proposing a conceptual framework for the migration of stream-processing \gls{pe}s in the fog.\\
The application-level approach proposed in this thesis represents a contrast to the virtualization level migration approaches taken in the majority of works on the migration of applications in the fog. The choice of virtualization level approaches can be attributed to their generality. As elaborated on in chapter \ref{lMigrationConcept}, the virtualization level approaches facilitate this generality. However, using an application-level approach in the use case of stream processing allows addressing intricacies of stream processing \gls{pe}s. This facilitates the fulfillment of the requirements.\\
While the works concerning state in data processing deploy application-level approaches for state handling, they do not address fog computing specific requirements. Additionally, only a small fraction of these works address the migration of the operator state, while most others focus on providing fault tolerance and scalability. This thesis combines measures for fault tolerance with a concept for the migration while addressing fog specific requirements at the same time.



\subsection{Future Work}
\label{lFutureWork}

During the writing of this thesis, several topics for future work were identified. Most of these topics have already been broached in the Discussion section (\ref{lDiscussion}).\\
Future research could explore the transfer of the developed conceptual framework to a more decentralized setting, without a centralized node that handles the global availability of state backups. This could be realized by distributing the state checkpoints to other nodes hosting \gls{pe}s, as proposed by Fernandez et al. \cite{CastroFernandez.2013}.\\
A logical next step to improve the conceptual framework and the implementation is to unify the \textit{\acrshort{pe} live migration} and the \textit{\acrshort{pe} restoration}. This would also allow for a performance improvement, as elaborated on in chapter \ref{lDiscussion}.\\
Before the implementation of the \textit{\acrshort{pe} restoration} is used, the handling of interrupted \gls{pe}s should be addressed. It is essential to guarantee that a supposedly interrupted \gls{pe} does not come back to life, meaning that it does not start processing events again.\\
The implementation could be tested and examined in a test scenario closer to a real-world application and under variation of factors not yet investigated in the evaluation to achieve a more comprehensive evaluation.\\
Moreover, future work in general should assess the migration of applications in fog computing further, developing a more general approach that allows the migration of stream processing \gls{pe}s and further applications.